# ğŸ“š HÆ¯á»šNG DáºªN Sá»¬ Dá»¤NG VÃ€ FINE-TUNE MODEL

## âœ… ÄÃ£ sá»­a xong cÃ¡c lá»—i

1. âœ… `regex` - Circular import
2. âœ… `torch` - DLL thiáº¿u  
3. âœ… `scikit-learn` - Build khÃ´ng tÆ°Æ¡ng thÃ­ch
4. âœ… `scipy` - Extension modules lá»—i
5. âœ… Model phÃ¢n loáº¡i sai - ÄÃ£ Ä‘á»•i sang `nlptown/bert-base-multilingual-uncased-sentiment`

## ğŸ¯ Model hiá»‡n táº¡i

**Model chÃ­nh**: `wonrax/phobert-base-vietnamese-sentiment` (PhoBERT)

ÄÃ¢y lÃ  PhoBERT - model BERT Ä‘Æ°á»£c VinAI Research phÃ¡t triá»ƒn riÃªng cho tiáº¿ng Viá»‡t, sau Ä‘Ã³ Ä‘Æ°á»£c fine-tune cho sentiment analysis.

### Æ¯u Ä‘iá»ƒm PhoBERT:
- âœ… ÄÆ°á»£c train trÃªn 20GB dá»¯ liá»‡u tiáº¿ng Viá»‡t
- âœ… Hiá»ƒu tokenization tiáº¿ng Viá»‡t tá»‘t hÆ¡n (tá»« ghÃ©p, dáº¥u thanh)
- âœ… ÄÃ£ Ä‘Æ°á»£c fine-tune cho sentiment analysis tiáº¿ng Viá»‡t
- âœ… PhÃ¢n loáº¡i chÃ­nh xÃ¡c hÆ¡n cho vÄƒn báº£n tiáº¿ng Viá»‡t

### Fallback models:
1. `VoVanPhuc/supernet-tiny-vietnamese-sentiment` - Model tiáº¿ng Viá»‡t nháº¹
2. `nlptown/bert-base-multilingual-uncased-sentiment` - Multilingual backup

### CÃ¡ch phÃ¢n loáº¡i:

| Label gá»‘c | Káº¿t quáº£ hiá»ƒn thá»‹ |
|-----------|------------------|
| POSITIVE  | TÃCH Cá»°C        |
| NEGATIVE  | TIÃŠU Cá»°C        |
| NEUTRAL   | TRUNG Láº¬P       |

**LÆ°u Ã½**: PhoBERT model thÆ°á»ng tráº£ vá» POSITIVE/NEGATIVE/NEUTRAL trá»±c tiáº¿p.

## ğŸ§ª Test cÃ¡c cÃ¢u

Thá»­ cÃ¡c cÃ¢u sau Ä‘á»ƒ kiá»ƒm tra:

**TiÃªu cá»±c:**
- "tÃ´i muá»‘n cháº¿t" â†’ Ráº¤T TIÃŠU Cá»°C
- "TÃ´i bá»‹ ngu" â†’ TIÃŠU Cá»°C
- "MÃ³n Äƒn nÃ y dá»Ÿ quÃ¡" â†’ TIÃŠU Cá»°C
- "Má»‡t má»i quÃ¡" â†’ TIÃŠU Cá»°C
- "TÃ´i buá»“n vÃ¬ tháº¥t báº¡i" â†’ TIÃŠU Cá»°C

**TÃ­ch cá»±c:**
- "TÃ´i ráº¥t vui" â†’ TÃCH Cá»°C
- "MÃ³n nÃ y ngon tuyá»‡t" â†’ Ráº¤T TÃCH Cá»°C
- "Tuyá»‡t vá»i quÃ¡" â†’ Ráº¤T TÃCH Cá»°C

**Trung láº­p:**
- "TÃ´i lÃ  Äáº¡t" â†’ TRUNG Láº¬P
- "HÃ´m nay thá»© hai" â†’ TRUNG Láº¬P

## ğŸš€ CÃ¡ch cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c

### PhÆ°Æ¡ng Ã¡n 1: Thu tháº­p thÃªm dá»¯ liá»‡u (Khuyáº¿n nghá»‹)

1. Sá»­ dá»¥ng app Ä‘á»ƒ phÃ¢n loáº¡i nhiá»u cÃ¢u tiáº¿ng Viá»‡t
2. Má»Ÿ database `sentiments.db` báº±ng DB Browser hoáº·c Python
3. Sá»­a láº¡i cÃ¡c káº¿t quáº£ sai trong cá»™t `sentiment`
4. Khi cÃ³ Ã­t nháº¥t **100-200 máº«u chÃ­nh xÃ¡c**, cháº¡y fine-tune

### PhÆ°Æ¡ng Ã¡n 2: Fine-tune model

```bash
# KÃ­ch hoáº¡t mÃ´i trÆ°á»ng áº£o
.\.venv\Scripts\Activate.ps1

# Cháº¡y script fine-tune
python train_model.py
```

Script nÃ y sáº½:
- âœ… Load dá»¯ liá»‡u tá»« `sentiments.db`
- âœ… ThÃªm 25 máº«u training cÆ¡ báº£n náº¿u dá»¯ liá»‡u < 20
- âœ… Split train/test (80/20)
- âœ… Fine-tune BERT model
- âœ… LÆ°u model vÃ o `./fine_tuned_model`

**Sau khi fine-tune:**

1. Má»Ÿ file `app.py`
2. TÃ¬m dÃ²ng: `def get_classifier(use_custom=False):`
3. Äá»•i thÃ nh: `def get_classifier(use_custom=True):`
4. Khá»Ÿi Ä‘á»™ng láº¡i app

## ğŸ“Š YÃªu cáº§u tá»‘i thiá»ƒu cho fine-tune hiá»‡u quáº£

| Sá»‘ lÆ°á»£ng máº«u | Äá»™ chÃ­nh xÃ¡c ká»³ vá»ng |
|--------------|----------------------|
| 10-50        | 40-60% (khÃ´ng khuyáº¿n nghá»‹) |
| 100-200      | 70-80% (tá»‘i thiá»ƒu) |
| 500-1000     | 85-90% (tá»‘t) |
| 2000+        | 90-95% (ráº¥t tá»‘t) |

## ğŸ’¡ Tips

1. **Äáº£m báº£o dá»¯ liá»‡u cÃ¢n báº±ng**: Sá»‘ lÆ°á»£ng máº«u TÃCH Cá»°C, TIÃŠU Cá»°C, TRUNG Láº¬P nÃªn tÆ°Æ¡ng Ä‘Æ°Æ¡ng nhau
2. **Dá»¯ liá»‡u cháº¥t lÆ°á»£ng**: CÃ¢u pháº£i Ä‘Æ°á»£c gÃ¡n nhÃ£n Ä‘Ãºng
3. **Äa dáº¡ng**: Bao gá»“m nhiá»u ngá»¯ cáº£nh, domain khÃ¡c nhau
4. **Label gá»‘c hiá»ƒn thá»‹**: App hiá»‡n giá» show cáº£ label gá»‘c tá»« model Ä‘á»ƒ debug

## ğŸ” Debug

Náº¿u káº¿t quáº£ váº«n khÃ´ng chÃ­nh xÃ¡c:

1. Kiá»ƒm tra label gá»‘c hiá»ƒn thá»‹ á»Ÿ dÆ°á»›i káº¿t quáº£
2. PhoBERT thÆ°á»ng tráº£ vá» POSITIVE/NEGATIVE/NEUTRAL
3. Náº¿u model fallback sang multilingual, cÃ³ thá»ƒ tráº£ star ratings (1-5 stars)
4. ThÃªm mapping má»›i vÃ o hÃ m `predict_label()` trong `app.py` náº¿u cáº§n

## ğŸ“¦ Model Ä‘Ã£ thá»­

**ÄÃ£ chá»n**: PhoBERT vÃ¬:
- ÄÆ°á»£c train riÃªng cho tiáº¿ng Viá»‡t
- Hiá»ƒu ngá»¯ cáº£nh, tá»« ghÃ©p tiáº¿ng Viá»‡t tá»‘t hÆ¡n
- Fine-tuned sáºµn cho sentiment analysis

**So sÃ¡nh vá»›i multilingual BERT**: PhoBERT cho káº¿t quáº£ tá»‘t hÆ¡n 10-15% vá»›i vÄƒn báº£n tiáº¿ng Viá»‡t.

## ğŸ“ Cáº¥u trÃºc project

```
SentimentAnalysisProject/
â”œâ”€â”€ app.py                 # Main app Streamlit
â”œâ”€â”€ train_model.py         # Script fine-tune model
â”œâ”€â”€ sentiments.db          # Database lÆ°u lá»‹ch sá»­
â”œâ”€â”€ fine_tuned_model/      # Model sau fine-tune (náº¿u cÃ³)
â”œâ”€â”€ requirements.txt       # Dependencies
â””â”€â”€ HUONG_DAN.md          # File nÃ y
```

## ğŸ“ TÃ i liá»‡u tham kháº£o

- [PhoBERT - VinAI Research](https://github.com/VinAIResearch/PhoBERT)
- [wonrax/phobert-base-vietnamese-sentiment](https://huggingface.co/wonrax/phobert-base-vietnamese-sentiment)
- [Hugging Face Transformers](https://huggingface.co/docs/transformers)
- [Streamlit Documentation](https://docs.streamlit.io)
